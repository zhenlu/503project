\documentclass[11pt]{amsart}
\usepackage{geometry}
\geometry{letterpaper}
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Project Proposal}
\author{Wenjing Yu, Lingyu Deng, Peng Wan, Zhen Lu}

\begin{document}
\maketitle
\section{Background}
Today, search engine plays an increasingly important role in our daily life. As graduate students, many of us have built search engines 
before using tools such as \emph{Apache Lucene}\footnote{For more details, see 
http://lucene.apache.org}. 

%The search engines technologies are well-developed by now and the most popular ones are classic algorithms.
%There are lots of tools providing frameworks to build search engines easily, such as \emph{Lucene}.

However, we are not very familiar with the parallelism inside search engines, since parallel algorithms
are packaged in these tools. In this project we will focus on some of the most well-known algorithm in search engine and implement them in a parallel way to have a better understanding of search engines' parallelism.

\section{Problem Description}
In modern search engines, there are 4 main parts, which include crawling web pages, indexing documents, 
ranking and querying. 

Web crawler obtains data from the web. Giving some starting URLs, a crawler downloads the
pages and parse the page to extract the URLs inside the page. And go on to download and parse the new URLs it obtained just now.

The most common method for indexing is to represent the documents using vector space model. This part
mainly focuses on the representation and building an inverted index for documents.

When it comes to rank, PageRank is the most popular algorithm to measure the importance of a page. 

At last, when a query is given, we can use the inverted index and calculated PageRank for each page
to get the result matches the query best and then returns a ranked list to user as the final result.

\section{Proposed Work}
Based on the main parts of search enginesï¼Œ this project can be divided into 4 parts as well. Details
for each part will be described below.

\begin{itemize}
	\item {\bf Crawling:} implement a parallel web crawler for obtaining data from some seed URLs.
	\item {\bf Indexing:} use vector space model for document representation, then build the inverted
	document index for the dataset. 
	\item {\bf Ranking:} implement a parallel version for PageRank algorithm.
	\item {\bf Querying:} build the parallel query system to get the search result for a specific query.
\end{itemize}

The techniques we decide to use to implement this project is MapReduce. We will use Hadoop as the MapReduce
implementation. So the language would be JAVA.

The reason why we choose MapReduce is that MapReduce is an elegant framework for parallel programming. And
applying MapReduce would make this project more interesting to work with. 

The main focus for this project will be on Ranking algorithm and Querying method. Crawling and indexing part
does not have much dependent data for each single document, that would make this easy to implement and less
interesting. However, calculating PageRank and search the related document for a query requires many steps
and they share lots of data. For example, when calculating PageRank, we need to use the result from previous
iteration to calculation the value in current iteration. That requires more techniques to handle data 
dependency.

\end{document}
